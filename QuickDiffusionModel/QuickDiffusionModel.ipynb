{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59c9742-5a7f-4317-bcab-8660acc70016",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "For more detail:\n",
    "https://tree.rocks/make-diffusion-model-from-scratch-easy-way-to-implement-quick-diffusion-model-e60d18fd0f2e\n",
    "\"\"\"\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import tensorflow as tf\n",
    "for gpu in tf.config.list_physical_devices('GPU'):\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379efde3-f91e-4cb5-a404-42ea52e3a4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from tqdm.auto import trange, tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ecf33b-edf2-41cf-adcd-9475d492522e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "X_train = X_train[y_train.squeeze() == 1]\n",
    "X_train = (X_train / 127.5) - 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0d2bcf-e69d-4147-96ca-e6bed75643de",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 32     # input image size, CIFAR-10 is 32x32\n",
    "BATCH_SIZE = 128  # for training batch size\n",
    "timesteps = 16    # how many steps for a noisy image into clear\n",
    "time_bar = 1 - np.linspace(0, 1.0, timesteps + 1) # linspace for timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aaa1fcf-a588-484b-99a2-a288a1a58a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(time_bar, label='Noise')\n",
    "plt.plot(1 - time_bar, label='Clarity')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7611759-27d1-418a-bd56-0436246f5863",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cvtImg(img):\n",
    "    img = img - img.min()\n",
    "    img = (img / img.max())\n",
    "    return img.astype(np.float32)\n",
    "\n",
    "def show_examples(x):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for i in range(25):\n",
    "        plt.subplot(5, 5, i+1)\n",
    "        img = cvtImg(x[i])\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "\n",
    "show_examples(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8c84b3-bd06-4f55-8d06-44b2e5bcf817",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_noise(x, t):\n",
    "    a = time_bar[t]      # base on t\n",
    "    b = time_bar[t + 1]  # image for t + 1\n",
    "    \n",
    "    noise = np.random.normal(size=x.shape)  # noise mask\n",
    "    a = a.reshape((-1, 1, 1, 1))\n",
    "    b = b.reshape((-1, 1, 1, 1))\n",
    "    img_a = x * (1 - a) + noise * a\n",
    "    img_b = x * (1 - b) + noise * b\n",
    "    return img_a, img_b\n",
    "    \n",
    "def generate_ts(num):\n",
    "    return np.random.randint(0, timesteps, size=num)\n",
    "\n",
    "# t = np.full((25,), timesteps - 1) # if you want see clarity\n",
    "# t = np.full((25,), 0)             # if you want see noisy\n",
    "t = generate_ts(25)             # random for training data\n",
    "a, b = forward_noise(X_train[:25], t)\n",
    "show_examples(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16f4531-2815-4345-921f-442bddebf150",
   "metadata": {},
   "outputs": [],
   "source": [
    "def block(x_img, x_ts):\n",
    "    x_parameter = layers.Conv2D(128, kernel_size=3, padding='same')(x_img)\n",
    "    x_parameter = layers.Activation('relu')(x_parameter)\n",
    "\n",
    "    time_parameter = layers.Dense(128)(x_ts)\n",
    "    time_parameter = layers.Activation('relu')(time_parameter)\n",
    "    time_parameter = layers.Reshape((1, 1, 128))(time_parameter)\n",
    "    x_parameter = x_parameter * time_parameter\n",
    "    \n",
    "    # -----\n",
    "    x_out = layers.Conv2D(128, kernel_size=3, padding='same')(x_img)\n",
    "    x_out = x_out + x_parameter\n",
    "    x_out = layers.LayerNormalization()(x_out)\n",
    "    x_out = layers.Activation('relu')(x_out)\n",
    "    \n",
    "    return x_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ad5f86-936a-4229-9902-98dd8366c803",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_model():\n",
    "    x = x_input = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3), name='x_input')\n",
    "    \n",
    "    x_ts = x_ts_input = layers.Input(shape=(1,), name='x_ts_input')\n",
    "    x_ts = layers.Dense(192)(x_ts)\n",
    "    x_ts = layers.LayerNormalization()(x_ts)\n",
    "    x_ts = layers.Activation('relu')(x_ts)\n",
    "    \n",
    "    # ----- left ( down ) -----\n",
    "    x = x32 = block(x, x_ts)\n",
    "    x = layers.MaxPool2D(2)(x)\n",
    "    \n",
    "    x = x16 = block(x, x_ts)\n",
    "    x = layers.MaxPool2D(2)(x)\n",
    "    \n",
    "    x = x8 = block(x, x_ts)\n",
    "    x = layers.MaxPool2D(2)(x)\n",
    "    \n",
    "    x = x4 = block(x, x_ts)\n",
    "    \n",
    "    # ----- MLP -----\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Concatenate()([x, x_ts])\n",
    "    x = layers.Dense(128)(x)\n",
    "    x = layers.LayerNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "\n",
    "    x = layers.Dense(4 * 4 * 32)(x)\n",
    "    x = layers.LayerNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Reshape((4, 4, 32))(x)\n",
    "    \n",
    "    # ----- right ( up ) -----\n",
    "    x = layers.Concatenate()([x, x4])\n",
    "    x = block(x, x_ts)\n",
    "    x = layers.UpSampling2D(2)(x)\n",
    "    \n",
    "    x = layers.Concatenate()([x, x8])\n",
    "    x = block(x, x_ts)\n",
    "    x = layers.UpSampling2D(2)(x)\n",
    "    \n",
    "    x = layers.Concatenate()([x, x16])\n",
    "    x = block(x, x_ts)\n",
    "    x = layers.UpSampling2D(2)(x)\n",
    "    \n",
    "    x = layers.Concatenate()([x, x32])\n",
    "    x = block(x, x_ts)\n",
    "    \n",
    "    # ----- output -----\n",
    "    x = layers.Conv2D(3, kernel_size=1, padding='same')(x)\n",
    "    model = tf.keras.models.Model([x_input, x_ts_input], x)\n",
    "    return model\n",
    "    \n",
    "\n",
    "model = make_model()\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abb6b35-a520-4fd6-8550-dd84603e3a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0008)\n",
    "loss_func = tf.keras.losses.MeanAbsoluteError()\n",
    "model.compile(loss=loss_func, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0040599-3ba4-4b84-ac36-d88b7456dd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x_idx=None):\n",
    "    x = np.random.normal(size=(32, IMG_SIZE, IMG_SIZE, 3))\n",
    "\n",
    "    for i in trange(timesteps):\n",
    "        t = i\n",
    "        x = model.predict([x, np.full((32), t)], verbose=0)\n",
    "    show_examples(x)\n",
    "\n",
    "predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0efa2b-72ab-4efa-8e89-8dac57c238b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_step():\n",
    "    xs = []\n",
    "    x = np.random.normal(size=(8, IMG_SIZE, IMG_SIZE, 3))\n",
    "\n",
    "    for i in trange(timesteps):\n",
    "        t = i\n",
    "        x = model.predict([x, np.full((8),  t)], verbose=0)\n",
    "        if i % 2 == 0:\n",
    "            xs.append(x[0])\n",
    "\n",
    "    plt.figure(figsize=(20, 2))\n",
    "    for i in range(len(xs)):\n",
    "        plt.subplot(1, len(xs), i+1)\n",
    "        plt.imshow(cvtImg(xs[i]))\n",
    "        plt.title(f'{i}')\n",
    "        plt.axis('off')\n",
    "\n",
    "predict_step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede500db-da1d-4b88-ab1d-07131e2a1823",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one(x_img):\n",
    "    x_ts = generate_ts(len(x_img))\n",
    "    x_a, x_b = forward_noise(x_img, x_ts)\n",
    "    loss = model.train_on_batch([x_a, x_ts], x_b)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ffea54-b7cb-43c7-8f6b-54ceccfbbe99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(R=50):\n",
    "    bar = trange(R)\n",
    "    total = 100\n",
    "    for i in bar:\n",
    "        for j in range(total):\n",
    "            x_img = X_train[np.random.randint(len(X_train), size=BATCH_SIZE)]\n",
    "            loss = train_one(x_img)\n",
    "            pg = (j / total) * 100\n",
    "            if j % 5 == 0:\n",
    "                bar.set_description(f'loss: {loss:.5f}, p: {pg:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0556441d-1498-4f32-bfae-56038503037d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b3b394-8312-47fe-a414-b2283ac752ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(10):\n",
    "    train()\n",
    "    # reduce learning rate for next training\n",
    "    model.optimizer.learning_rate = max(0.000001, model.optimizer.learning_rate * 0.9)\n",
    "\n",
    "    # show result \n",
    "    predict()\n",
    "    predict_step()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e55243-68dc-4066-8ccc-bdf51609900b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7376635a-846c-46a6-bbf3-f5a522c3f0b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
