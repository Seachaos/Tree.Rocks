{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819164d2-1de5-43d7-b782-4f3cb029c6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "For more detail:\n",
    "https://seachaos.com/transfer-learning-with-gan-cyclegan-from-scratch-1afc9ab7c7d1\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0753e7ea-c484-42e7-9454-c5e7889eb813",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import trange, tqdm\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ab0077-af4e-4744-837b-84e0106a28f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, dataset_info = tfds.load('cycle_gan/horse2zebra', with_info=True, as_supervised=True)\n",
    "\n",
    "train_a, train_b = dataset['trainA'], dataset['trainB']\n",
    "test_a, test_b = dataset['testA'], dataset['testB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb1ea8d-e254-4c46-8267-ae9a2a061871",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32  # set to 16 or less, if you don't have enough VRAM.\n",
    "\n",
    "img_size = 128\n",
    "big_img_size = 192\n",
    "\n",
    "LR = 0.00012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7199f5ed-3c1d-41e1-93e9-6d1245b2fbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _process_img(image, label):\n",
    "        image = tf.image.resize(image, (big_img_size, big_img_size))\n",
    "        image = (image / 127.5) - 1.0\n",
    "        return image, label\n",
    "\n",
    "def prepare_data(data, b=batch_size):\n",
    "    return data \\\n",
    "        .cache() \\\n",
    "        .map(_process_img, num_parallel_calls=tf.data.AUTOTUNE) \\\n",
    "        .shuffle(b) \\\n",
    "        .batch(b)\n",
    "\n",
    "ds_train_a, ds_train_b = prepare_data(train_a), prepare_data(train_b)\n",
    "ds_test_a, ds_test_b = prepare_data(test_a), prepare_data(test_b)\n",
    "\n",
    "\n",
    "x_train_sets = [\n",
    "    tf.concat([a[0] for a in ds_train_a], axis=0),\n",
    "    tf.concat([b[0] for b in ds_train_b], axis=0),\n",
    "]\n",
    "\n",
    "x_test_sets = [\n",
    "    tf.concat([a[0] for a in ds_test_a], axis=0),\n",
    "    tf.concat([b[0] for b in ds_test_b], axis=0),\n",
    "]\n",
    "\n",
    "print('x_train_all: ', sum([s.shape[0] for s in x_train_sets]), x_train_sets[0].numpy().min(), x_train_sets[0].numpy().max())\n",
    "print('x_test_all: ', sum([s.shape[0] for s in x_test_sets]), x_test_sets[0].numpy().min(), x_test_sets[0].numpy().max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3510e0e9-881c-4100-9e32-2a3d756334bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _rand_pick(data, augment=True):\n",
    "    idx = np.random.choice(range(len(data)), size=batch_size, replace=False)\n",
    "    x = tf.gather(data, idx, axis=0)\n",
    "    if augment:\n",
    "        cx = random.uniform(1.0, 1.5)\n",
    "        cy = random.uniform(1.0, 1.5)\n",
    "        x = tf.image.random_crop(x, size=(batch_size, int(img_size * cx), int(img_size * cy), 3))\n",
    "        x = tf.image.random_flip_left_right(x)\n",
    "    x = tf.image.resize(x, (img_size, img_size))\n",
    "    return x\n",
    "\n",
    "def get_x_train():\n",
    "    xa = _rand_pick(x_train_sets[0])\n",
    "    xb = _rand_pick(x_train_sets[1])\n",
    "    return xa, xb\n",
    "\n",
    "def get_x_test():\n",
    "    xa = _rand_pick(x_test_sets[0], augment=False)\n",
    "    xb = _rand_pick(x_test_sets[1], augment=False)\n",
    "    return xa, xb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523f1340-a64c-4b29-b38a-1adebd6d8034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify \"get_x_train\" output\n",
    "def cvtImg(x):\n",
    "    return (x + 1.0) / 2.0\n",
    "\n",
    "def show(x, S=12):\n",
    "    x = cvtImg(x)\n",
    "    plt.figure(figsize=(15, 3))\n",
    "    for i in range(min(len(x), S)):\n",
    "        plt.subplot(1, S, i + 1)\n",
    "        plt.imshow(x[i])\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "for _ in range(1):\n",
    "    xa, xb = get_x_train()\n",
    "    xa = xa.numpy()\n",
    "    print(xa.min(), xa.max(), xa.shape)\n",
    "    show(xa)\n",
    "    show(xb.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afeefba2-eeb5-4664-b0d0-da7b71236951",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759efadc-7519-4686-bc37-faddc22e373d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.VGG16(input_shape=(img_size, img_size, 3), include_top=False)\n",
    "\n",
    "x = x_input = base_model.input\n",
    "\n",
    "outputs = [\n",
    "    'block2_conv2',\n",
    "    'block3_conv3',\n",
    "    'block4_conv3',\n",
    "    'block5_conv1',\n",
    "    'block5_pool',\n",
    "]\n",
    "\n",
    "x_output = [base_model.get_layer(n).output for n in outputs]\n",
    "base_model = tf.keras.models.Model(x_input, x_output)\n",
    "\n",
    "base_model.trainable = False\n",
    "\n",
    "# base_model.summary() # if you want see more detail about VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0f165c-8035-4c91-9a8a-1cf211974687",
   "metadata": {},
   "outputs": [],
   "source": [
    "act_name = 'gelu'\n",
    "\n",
    "def act(x):\n",
    "    x = layers.LayerNormalization()(x)\n",
    "    x = layers.Activation(act_name)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431e3e76-21ca-4367-bd64-331f5f795d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_with_cmd(x_img_input, x_cmd, f=64, sp=4):\n",
    "    x = layers.Dense(128)(x_cmd)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(act_name)(x)\n",
    "    \n",
    "    x = layers.Dense(f)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('sigmoid')(x)\n",
    "\n",
    "    x_g = layers.Reshape((1, 1, f))(x)\n",
    "\n",
    "    # ---\n",
    "\n",
    "    x = layers.Conv2D(f, kernel_size=3, padding='same')(x_img_input)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(act_name)(x)\n",
    "    x =  x * x_g\n",
    "\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1265c2df-f766-4fa6-a13b-ef5a5405da73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gen_model():\n",
    "    # img input\n",
    "    x_input = layers.Input(shape=(img_size, img_size, 3))\n",
    "\n",
    "    # load base model\n",
    "    x_base_out = base_model(x_input)\n",
    "    [x64, x32, x16, x8, x4] = x_base_out\n",
    "\n",
    "\n",
    "    # x_cmd\n",
    "    x = x4\n",
    "    x = layers.Conv2D(256, kernel_size=3, padding='same')(x)\n",
    "    x = act(x)\n",
    "\n",
    "    x = layers.GlobalMaxPool2D()(x)\n",
    "\n",
    "\n",
    "    x = layers.Dense(128)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(act_name)(x)\n",
    "    x_cmd = x\n",
    "\n",
    "    \n",
    "    # GAN up\n",
    "    x = conv_with_cmd(x4, x_cmd, f=512)\n",
    "\n",
    "    # if you don't have enought VRAM, try reduce filters\n",
    "    for i, (x_cat, f) in enumerate([\n",
    "        (x8, 512),\n",
    "        (x16, 384),\n",
    "        (x32, 256),\n",
    "        (x64, 256),\n",
    "        (x_input, 256),\n",
    "    ]):\n",
    "        x = layers.UpSampling2D(2)(x)\n",
    "        x = layers.Concatenate()([x, x_cat])\n",
    "        x = conv_with_cmd(x, x_cmd, f=f)\n",
    " \n",
    "    # final output\n",
    "    x = layers.Conv2D(3, kernel_size=3, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('tanh')(x)\n",
    "\n",
    "    return tf.keras.models.Model(x_input, x)\n",
    "\n",
    "gen = create_gen_model()\n",
    "# gen.summary() # if you want see more detail about model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77e77e0-025e-4e82-8007-1d374e039c2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50751b1-97d4-4dd6-8a22-b3ddb04b02ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dis_model():\n",
    "    x = x_input = layers.Input(shape=(img_size, img_size, 3))\n",
    "\n",
    "    [x64, x32, x16, x8, x4] = base_model(x_input)\n",
    "\n",
    "    x = x8\n",
    "    x = layers.Conv2D(512, kernel_size=3, padding='same')(x)\n",
    "    x = act(x)\n",
    "    x = layers.MaxPool2D()(x)\n",
    "    \n",
    "    x = layers.Concatenate()([x, x4])\n",
    "    x = layers.Conv2D(512, kernel_size=3, padding='same')(x)\n",
    "    x = act(x)\n",
    "    \n",
    "    x = layers.GlobalMaxPool2D()(x)\n",
    "\n",
    "    x = layers.Dense(384)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(act_name)(x)\n",
    "    \n",
    "    x = layers.Dense(128)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(act_name)(x)\n",
    "    \n",
    "    x = layers.Dense(4)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('softmax')(x)\n",
    "    \n",
    "    return tf.keras.models.Model(x_input, x)\n",
    "\n",
    "dis = create_dis_model()\n",
    "# dis.summary() # if you want see more detail about model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70df3a9e-c304-49e7-aab9-b9ce9556a559",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_false_a = np.zeros(batch_size)\n",
    "y_false_b = np.full_like(y_false_a, 1)\n",
    "y_true_a = np.full_like(y_false_a, 2)\n",
    "y_true_b = np.full_like(y_false_a, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c835790e-3e10-47a9-9b33-94b5e72d3332",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_gen = tf.keras.optimizers.AdamW(learning_rate=LR)\n",
    "opt_dis = tf.keras.optimizers.AdamW(learning_rate=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1228f961-db1d-47d6-b4f6-d7c74da58cdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9af8d3a-0ba7-4e2e-a1eb-9089972fdb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def _train_dis(x, y_t):\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        y_p = dis(x)\n",
    "        loss = tf.losses.sparse_categorical_crossentropy(y_t, y_p)\n",
    "        loss = tf.reduce_mean(loss)\n",
    "\n",
    "    g = tape.gradient(loss, dis.trainable_variables)\n",
    "    g = zip(g, dis.trainable_variables)\n",
    "    opt_dis.apply_gradients(g)\n",
    "    \n",
    "    return float(loss)\n",
    "\n",
    "def train_dis():\n",
    "    dis.trainable = True\n",
    "    gen.trainable = False\n",
    "    base_model.trainable = False\n",
    "\n",
    "    xa, xb = get_x_train()\n",
    "\n",
    "    # train dis A\n",
    "    xa_fake = gen.predict(xb, verbose=False)\n",
    "    loss_a = \\\n",
    "        _train_dis(xa, y_true_a) + \\\n",
    "        _train_dis(xa_fake, y_false_a)\n",
    "\n",
    "    # train dis B\n",
    "    xb_fake = gen.predict(xa, verbose=False)\n",
    "    loss_b = \\\n",
    "        _train_dis(xb, y_true_b) + \\\n",
    "        _train_dis(xb_fake, y_false_b)\n",
    "    \n",
    "    return float(loss_a), float(loss_b)\n",
    "\n",
    "train_dis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd45ade5-a3f5-4023-b7b0-cb655a8bcaf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4febb4c-0207-4019-8655-2912f1657243",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def _train_gen_cycle(x_real, y_t, y_f):\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        x_fake = gen(x_real) # forward\n",
    "        \n",
    "        # discriminator\n",
    "        y_p = dis(x_fake)\n",
    "        loss_dis = tf.losses.sparse_categorical_crossentropy(y_t, y_p)\n",
    "\n",
    "        # revert\n",
    "        x_revert = gen(x_fake)\n",
    "        loss_revert = tf.losses.mse(x_real, x_revert)\n",
    "\n",
    "        loss = tf.reduce_mean(loss_dis) + tf.reduce_mean(loss_revert)\n",
    "\n",
    "\n",
    "    g = tape.gradient(loss, gen.trainable_variables)\n",
    "    g = zip(g, gen.trainable_variables)\n",
    "    opt_gen.apply_gradients(g)\n",
    "\n",
    "    return float(loss)\n",
    "\n",
    "def train_gen():\n",
    "    gen.trainable = True\n",
    "    dis.trainable = False\n",
    "    base_model.trainable = False\n",
    "\n",
    "    xa, xb = get_x_train()\n",
    "\n",
    "    loss_a = \\\n",
    "        _train_gen_cycle(xa, y_true_b, y_true_a)\n",
    "    \n",
    "    loss_b = \\\n",
    "        _train_gen_cycle(xb, y_true_a, y_true_b)\n",
    "\n",
    "    return float(loss_a), float(loss_b)\n",
    "\n",
    "train_gen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be130f5c-e6e0-409f-9843-8c9ba4428056",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a5cb7f-9a1b-4af1-90f8-04ffa75be7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _preview(x_real, title=None):\n",
    "    x_fake = gen.predict(x_real, verbose=0)\n",
    "    x_real = cvtImg(x_real.numpy())\n",
    "    x_fake = cvtImg(x_fake)\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(25, 5))\n",
    "    if title:\n",
    "        plt.suptitle(title)\n",
    "    s = min(batch_size, 9)\n",
    "    for i in range(s):\n",
    "        plt.subplot(2, s, i + 1)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(x_real[i])\n",
    "        plt.subplot(2, s, i + 1 + s)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(x_fake[i])\n",
    "    plt.show()\n",
    "\n",
    "def preview(useTest=True):\n",
    "    if useTest:\n",
    "        xa, xb = get_x_test()\n",
    "    else:\n",
    "        xa, xb = get_x_train()\n",
    "    _preview(xa[:9], 'A -> B')\n",
    "    _preview(xb[:9], 'B -> A')\n",
    "\n",
    "preview()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d7a0bb-9d42-4342-86e0-6a12d2f4e734",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30476330-5921-47f0-8a80-0a604c42c8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    bar = trange(200)\n",
    "    for _ in bar:\n",
    "        lda, ldb = train_dis()\n",
    "        lga, lgb = train_gen()\n",
    "        msg = f'gen: {lga:.5f}, {lgb:.5f} | dis: {lda:.5f}, {ldb:.5f}'\n",
    "        bar.set_description(msg)\n",
    "\n",
    "def go():\n",
    "    for i in trange(50):\n",
    "        train()\n",
    "        if i % 5 == 0:\n",
    "            preview()\n",
    "        \n",
    "        opt_dis.learning_rate = opt_dis.learning_rate * 0.98\n",
    "        opt_gen.learning_rate = opt_gen.learning_rate * 0.98\n",
    "        lg = opt_gen.learning_rate.numpy()\n",
    "        ld = opt_dis.learning_rate.numpy()\n",
    "        print(f'run: {i}')\n",
    "        print(f'LR gen: {lg:.7f}')\n",
    "        print(f'LR dis: {ld:.7f}')\n",
    "\n",
    "\n",
    "go()\n",
    "preview()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c1c063-4cde-4241-bc28-3133bc821029",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36eadd51-6ea7-4a4b-9128-3084d903f852",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e8406e-3255-4884-8231-d20b16d09d84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
